{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_yiADAIK4aM"
      },
      "source": [
        "# Training Neural Networks with Keras\n",
        "\n",
        "Welcome to the first practical session of the course! In this session, we will learn how to train neural networks with Keras. We will start with a simple example of a feedforward neural network for classification and then we will study the impact of the initialization of the weights on the convergence of the training algorithm.\n",
        "\n",
        "Keras is a high-level neural network API, built on top of TensorFlow 2.0. It provides a user-friendly interface to build, train and deploy deep learning models. Keras is designed to be modular, fast and easy to use.\n",
        "\n",
        "Throughout this course, we will focus on using Keras and TensorFlow for building and training neural networks. However, there are other popular deep learning frameworks such as PyTorch, MXNet, CNTK, etc. that you can also use to build and train neural networks.\n",
        "\n",
        "In order to use our code on Google Colab, we will need to ensure that any required packages are installed. We will use the following packages in this session:\n",
        "\n",
        "- `tensorflow`: an open-source library for numerical computation and large-scale machine learning.\n",
        "- `matplotlib`: a plotting library for the Python programming language and its numerical mathematics extension NumPy.\n",
        "- `numpy`: a library for scientific computing in Python.\n",
        "- `scikit-learn`: a machine learning library for the Python programming language.\n",
        "- `pandas`: a library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
        "\n",
        "Today, we will be working with the famous MNIST dataset. MNIST (Modified National Institute of Standards and Technology) is a database of low resolution images of handwritten digits. The history here is interesting - the dataset was originally created in the 1980s, when researchers from the aforementioned institute collected samples from American Census Bureau employees and high school students. The dataset was then modified in the 1990s (hence the M in MNIST), and has since become a popular benchmark for machine learning algorithms.\n",
        "\n",
        "The dataset contains images, each of which is a 28x28 grayscale image of a handwritten digit. The goal is to classify each image into one of the 10 possible classes (0-9).\n",
        "\n",
        "![MNIST](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
        "\n",
        "The Scikit-Learn library provides a convenient function to download and load the MNIST dataset. The following cell will download the dataset. Then we will take a look at the shape of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6bmp1aTLK4aO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# Load the MNIST digits dataset using scikit-learn's load_digits() function.\n",
        "digits = load_digits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nddJF5dFK4aO",
        "outputId": "fbf1b94b-da30-4541-9e57-768f77b6a956"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Expected output: (1797, 8, 8). 1797 images in the dataset, and each image is an 8x8 pixel array.\n",
        "digits.images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qCaBk_SlK4aO"
      },
      "source": [
        "This means that we have 1797 images, each of which is a 8x8 image. For basic image processing, we will need to flatten the images into a 1D array. In this case, Scikit-Learn has already provided the data in this format too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1DGFPmvK4aP",
        "outputId": "e5674cf6-3a6b-44a2-b9d5-d158f862153e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# The output (1797, 64) shows that there are 1797 samples.\n",
        "# Each sample is represented as a 1D array of 64 features\n",
        "# (which is the result of flattening the 8x8 images).\n",
        "digits.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yMX7-ByyK4aP"
      },
      "source": [
        "For each image, we also have the corresponding label (or target, or class) in `digits.target`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9kVx4BDK4aP",
        "outputId": "ab98979d-c1df-42fc-d994-d8594ee5312f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "# 1797 target labels, one for each image in the dataset.\n",
        "digits.target.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ksH-L7A9K4aP"
      },
      "source": [
        "We can take a look at some random images from the dataset. The following cell will select 9 random images and plot them in a 3x3 grid (meaning that you can rerun the cell to see different images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "MkyOqL7DK4aP",
        "outputId": "e9c3ab19-c4f4-4840-e66b-73f79cf65de0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Selecting 9 random indices\n",
        "random_indices = np.random.choice(len(digits.images), 9, replace=False)\n",
        "\n",
        "# Creating a 3x3 grid plot\n",
        "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(digits.images[random_indices[i]], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f\"Label: {digits.target[random_indices[i]]}\")\n",
        "\n",
        "    # Removing axis labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "WPLBiHpLK4aP"
      },
      "source": [
        "As you can see, these images are very low resolution. This is because they were originally scanned from paper forms, and then scaled down to 8x8 pixels. This is a common problem in machine learning - the quality of the data is often a limiting factor in the performance of the model. In this case, the low resolution of the images makes it difficult to distinguish between some digits, even for humans. For example, the following images are all labelled as 9, but they look very different:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "QC68ZZ8DK4aQ",
        "outputId": "c652513d-6def-44e1-a32b-41a422ccab0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Selecting 9 random indices of images labelled as 9\n",
        "random_indices = np.random.choice(np.where(digits.target == 9)[0], 9, replace=False)\n",
        "\n",
        "# Creating a 3x3 grid plot\n",
        "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(digits.images[random_indices[i]], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f\"Label: {digits.target[random_indices[i]]}\")\n",
        "\n",
        "    # Removing axis labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "iO31qKJ7K4aQ"
      },
      "source": [
        "While we are plotting the samples as images, remember that our model is only going to see a 1D array of numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh_1gqhZK4aQ"
      },
      "source": [
        "## Train / Test Split\n",
        "\n",
        "In order to understand how well our model performs on _new_ data, we need to split our dataset into a training set and a test set. The training set will be used to train the model, and the test set will be used to evaluate the performance of the model.\n",
        "\n",
        "Let's keep some held-out data to be able to measure the generalization performance of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AbbEvMJ7K4aQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train: The features for the training set.\n",
        "# X_test: The features for the test set.\n",
        "# y_train: The labels for the training set.\n",
        "# y_test: The labels for the test set.\n",
        "# digits.data: This is the input data (the flattened images).\n",
        "# digits.target: This is the target data (the labels).\n",
        "# test_size=0.2: This specifies that 20% of the data should be used for the test set, and the remaining 80% for the training set.\n",
        "# random_state=42: This ensures that the data split is the same every time the code is run, making the results reproducible.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    digits.data,\n",
        "    digits.target,\n",
        "    test_size=0.2, # 20% of the data is used for testing\n",
        "    random_state=42 # Providing a value here means getting the same \"random\" split every time\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "P30OF5PFK4aQ"
      },
      "source": [
        "Let's confirm that the data has been split correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k78NjhYzK4aQ",
        "outputId": "25177d76-1fb3-41fc-c3c1-57bb4b08b3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1437, 64)\n",
            "y_train shape: (1437,)\n",
            "X_test shape: (360, 64)\n",
            "y_test shape: (360,)\n"
          ]
        }
      ],
      "source": [
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "TBS45pObK4aQ"
      },
      "source": [
        "This is what we expected to see. It's always good to check as you go, to make sure that you haven't made a mistake somewhere - this is something that working in a notebook like this makes it easy to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs-dOs5tK4aR"
      },
      "source": [
        "## Preprocessing of the Target Data\n",
        "\n",
        "The labels that we have are integers between 0 and 9. However, we want to train a neural network to classify the images into one of 10 classes. It can be a little counter-intuitive because we are dealing with numbers, but our classes are not ordinal.\n",
        "\n",
        "What do we mean by that? Let's imagine we were trying to predict the height of a building (separated into classes) from images. If a given building was actually 10m tall, and our model predicted 9m, we would consider that to be a better prediction than if it predicted 1m. This is because the classes are ordinal - there is meaning in the difference between the classes.\n",
        "\n",
        "In our case, even though we are dealing with numbers, the classes are not ordinal. If a given image is actually a 9, and our model predicts 8, we would consider that to be just as bad as if it predicted 1. This is because the classes are not ordered, and the difference between the classes is not meaningful.\n",
        "\n",
        "Because of this, we need to convert our labels from an integer value into a one-hot encoded vector. This means that each label will be represented as a vector of length 10, with a 1 in the position corresponding to the class, and 0s everywhere else. For example, the label 9 would be represented as `[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]`. This is a common way of representing categorical data in machine learning. By doing this, we ensure that our model is taught the correct relationship between the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlLrZrDEK4aR",
        "outputId": "7e72e276-0f8b-4391-d08a-855b52457b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before one-hot encoding: 6\n",
            "After one-hot encoding: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# One-hot encoding represents each digit as a distinct category.\n",
        "# This is more appropriate for training a classification model.\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Print the value of the first training label before one-hot encoding to show the original format (an integer).\n",
        "print(f'Before one-hot encoding: {y_train[0]}')\n",
        "\n",
        "# Convert the training labels (y_train) and testing labels (y_test) into one-hot encoded vectors.\n",
        "# num_classes=10 specifies that there are 10 possible classes (digits 0-9).\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Print the first training label again after one-hot encoding\n",
        "# to show the new format (a vector with a 1 in the position corresponding to the class).\n",
        "print(f'After one-hot encoding: {y_train[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqaSAh3RK4aR"
      },
      "source": [
        "## Feed Forward Neural Networks with Keras\n",
        "\n",
        "Now that we have prepared our data, it's time to build a simple neural network! In this section, we will use the Keras API to build a simple feed forward neural network. We will then train the model on the MNIST dataset, and evaluate its performance on the test set.\n",
        "\n",
        "In most modern deep learning frameworks, the process of building a model can be broken down into a few steps:\n",
        "\n",
        "- Define the model architecture: this is where we define the layers of the model, and how they are connected to each other.\n",
        "- Compile the model: this is where we define the loss function, the optimizer, and the metrics that we want to use to evaluate the model.\n",
        "- Train the model: this is where we train the model on the training data.\n",
        "\n",
        "Let's start with defining the model architecture. There are two ways to do this in Keras - the Sequential API and the Functional API. The Sequential API is the simplest way to build a model, and is suitable for most use cases. The Functional API is more flexible, and allows you to build more complex models. We will start with the Sequential API, and then we will look at the Functional API later in the course.\n",
        "\n",
        "Our simple neural network will be \"fully-connected\". This means that each neuron in a given layer is connected to every neuron in the next layer. This is also known as a \"dense\" layer. We will use the `Dense` class from Keras to define our layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "kI9zRZYTK4aR",
        "outputId": "21c43913-746b-4e3f-9bdb-701f165b9666"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Initializes a Sequential model, which is a linear stack of layers.\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer specifying the shape of the input data (64 features).\n",
        "model.add(Input(shape=(64,)))  # Input tensor specifying the shape\n",
        "\n",
        "# First hidden layer with 64 neurons and the ReLU activation function.\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Second hidden layer with 64 neurons and the ReLU activation function.\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Output layer with 10 neurons (for the 10 digits) and the softmax activation function,\n",
        "# which outputs a probability distribution over the classes.\n",
        "model.add(Dense(10, activation='softmax'))  # 10 neurons, softmax activation\n",
        "\n",
        "# Print a summary of the model's architecture including the number of parameters in each layer.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "bR8Gb1WzK4aR"
      },
      "source": [
        "Congratulations! You have just built your first neural network with Keras. As we can confirm from the `model.summary()` output, our model has 3 layers. The first layer has 64 neurons, the second layer has 64 neurons, and the output layer has 10 neurons. The output layer uses the softmax activation function, which is commonly used for multi-class classification problems. The other layers use the ReLU activation function, which is commonly used for hidden layers in neural networks.\n",
        "\n",
        "Next, we need to compile the model. This is where we define the loss function, the optimizer, and the metrics that we want to use to evaluate the model. We will use the `compile` method of the model to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uViL5uL5K4aR"
      },
      "outputs": [],
      "source": [
        "# Configure the learning process.\n",
        "# loss='categorical_crossentropy': This specifies the loss function to be used. 'categorical_crossentropy' is suitable for multi-class classification problems where the labels are one-hot encoded.\n",
        "# optimizer=SGD(learning_rate=0.001): This specifies the optimizer to use for updating the model's weights during training. In this case, it's the SGD optimizer with a learning rate of 0.001.\n",
        "# metrics=['accuracy']: This specifies the metrics to be evaluated during training and testing. 'accuracy' calculates the percentage of correctly classified samples.\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # Loss function\n",
        "    optimizer='sgd', # Optimizer\n",
        "    metrics=['accuracy'] # Metrics to evaluate the model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1aUus5g0K4aS"
      },
      "source": [
        "Because we are predicting which class a sample belongs to, we will use the `categorical_crossentropy` function. This loss function is commonly used for multi-class classification problems.\n",
        "\n",
        "For our optimizer, we are using the standard stochastic gradient descent (SGD) algorithm. This is a simple optimizer that works well for many problems. We will look at more advanced optimizers later in the course.\n",
        "\n",
        "Finally, we are using the `accuracy` metric to evaluate the model. This is a common metric for classification problems, and it is simply the fraction of samples that are correctly classified. This is an easier metric for us to understand, but it's not quite as useful for actually training the model (for example, it doesn't tell us how \"confident\" the model is in its predictions).\n",
        "\n",
        "Now that we have (a) defined the model architecture and (b) compiled the model, we are ready to train the model. We will use the `fit` method of the model to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pZXk2pdK4aS",
        "outputId": "2f7c0e86-4d81-4a6b-b134-88d59671fd07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3800 - loss: 2.6847 - val_accuracy: 0.8368 - val_loss: 0.5446\n",
            "Epoch 2/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.4882 - val_accuracy: 0.9097 - val_loss: 0.3300\n",
            "Epoch 3/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9202 - loss: 0.2895 - val_accuracy: 0.9132 - val_loss: 0.2613\n",
            "Epoch 4/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9541 - loss: 0.1874 - val_accuracy: 0.9444 - val_loss: 0.2125\n",
            "Epoch 5/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9592 - loss: 0.1703 - val_accuracy: 0.9132 - val_loss: 0.1943\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e57a3431400>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Start the training process.\n",
        "# X_train: This is the training data (the features).\n",
        "# y_train: This is the training labels (the one-hot encoded digits).\n",
        "# epochs=5: This specifies the number of times the model will iterate over the entire training dataset.\n",
        "# batch_size=32: This determines the number of samples per gradient update during training.\n",
        "# validation_split=0.2: This reserves 20% of the training data to be used as validation data.\n",
        "# The model's performance on this data is evaluated at the end of each epoch, providing insight into how well the model generalizes to unseen data during training.\n",
        "\n",
        "model.fit(\n",
        "    X_train, # Training data\n",
        "    y_train, # Training labels\n",
        "    epochs=5, # Number of epochs\n",
        "    batch_size=32, # Number of samples per batch\n",
        "    validation_split=0.2 # Use 20% of the data for validation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "(X_train.shape[0] * 0.8) / 32\n",
        "\n",
        "NUM_TRAINING_SAMPLES = int(X_train.shape[0] * 0.8)\n",
        "NUM_TRAINING_SAMPLES\n",
        "\n",
        "print(f\"Number of training samples: {NUM_TRAINING_SAMPLES}\")\n",
        "print(f\"Number of validation samples: {X_train.shape[0] - NUM_TRAINING_SAMPLES}\")\n",
        "# Batch sizes\n",
        "print(f\"Batch size: {32}\")\n",
        "# Number of steps\n",
        "print(f\"Number of steps: {NUM_TRAINING_SAMPLES // 32}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_gNjnnGMOCk",
        "outputId": "dde6514e-073f-4af4-9ec1-d2c48e040ddd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 1149\n",
            "Number of validation samples: 288\n",
            "Batch size: 32\n",
            "Number of steps: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pfFGIBPyK4aS"
      },
      "source": [
        "We have now trained our model! We can see that the model has been trained for 5 epochs, and the loss and accuracy have been printed for each epoch. We can also see that the model has been evaluated on the validation data at the end of each epoch. This is useful for us to see how the model is performing on data that it hasn't seen during training.\n",
        "\n",
        "Once the model is trained, it's time to evaluate the model on the test set. We can use the `evaluate` method of the model to do this. If you were building a model for a real-world application, this is the very last thing you would do, and the result here would be the figure you'd report in your paper or presentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrIEtenhK4aS",
        "outputId": "22acb19d-60e8-4320-8230-fe345210673c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1789  \n",
            "Loss:     0.22\n",
            "Accuracy: 93.33%\n"
          ]
        }
      ],
      "source": [
        "# Display the final loss value after the model has been evaluated on the test set.\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Loss:     {loss:.2f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1QZHWJoOK4aS"
      },
      "source": [
        "Hopefully you have achieved an accuracy of around 95%. This is pretty good, but we can do better! In the next section, we will look at how we can improve the performance of our model by using a more advanced optimizer. But before we get there, let's do one other thing - let's look at the predictions that our model is making on the test set. When you are building a model, it's often useful to have a look at some of the examples your model is getting wrong. Sometimes this can reveal problems with the data, or it can give you ideas for how to improve your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "xlyqS50rK4aS",
        "outputId": "35a60b7d-5ce1-481d-b517-17c61065c415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get the predictions for the test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Get the index of the largest probability (i.e. the predicted class)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
        "\n",
        "# Get the misclassified samples themselves\n",
        "misclassified_samples = X_test[misclassified_indices]\n",
        "misclassified_labels = np.argmax(y_test[misclassified_indices], axis=1)\n",
        "\n",
        "# Pick 9 random misclassified samples\n",
        "random_indices = np.random.choice(len(misclassified_indices), 9, replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(misclassified_samples[random_indices[i]].reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f\"Pred: {predicted_classes[misclassified_indices[random_indices[i]]]}, Real: {misclassified_labels[random_indices[i]]}\")\n",
        "\n",
        "    # Removing axis labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "YAQnkzVfK4aS"
      },
      "source": [
        "What do you think? Would you have made the same mistakes as the model? Determining whether the mistakes are \"understandable\" is a rough way of seeing if you could improve the model further, or if this is the best you can do with the data you have."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhFqBn5QK4aS"
      },
      "source": [
        "### b) Exercises: Impact of the Optimizer\n",
        "\n",
        "In this section, you will play around with the optimizer and see how it affects the performance of the model. We will start with the standard SGD optimizer, and then we will look at more advanced optimizers.\n",
        "\n",
        "1. Try decreasing the learning rate of the SGD optimizer by a factor of 10, or 100. What do you observe?\n",
        "2. Try increasing the learning rate of the SGD optimizer. What happens?\n",
        "3. The SGD optimizer has a momentum parameter. In a nutshell, this parameter controls how much the gradient from the previous step affects the current step. Try enabling momentum in the SGD optimizer with a value of 0.9. What happens?\n",
        "  \n",
        "**Notes**:\n",
        "\n",
        "The keras API documentation is available at:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras\n",
        "\n",
        "It is also possible to learn more about the parameters of a class by using the question mark: type and evaluate:\n",
        "\n",
        "```python\n",
        "optimizers.SGD?\n",
        "```\n",
        "\n",
        "in a jupyter notebook cell.\n",
        "\n",
        "It is also possible to type the beginning of a function call / constructor and type \"shift-tab\" after the opening paren:\n",
        "\n",
        "```python\n",
        "optimizers.SGD(<shift-tab>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "D_nOk9BOK4aT",
        "outputId": "084c692c-97c0-4bc6-ca21-1eac5850621a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1141 - loss: 5.3885 - val_accuracy: 0.1806 - val_loss: 2.5976\n",
            "Epoch 2/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2652 - loss: 2.3079 - val_accuracy: 0.3889 - val_loss: 1.8221\n",
            "Epoch 3/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4760 - loss: 1.6484 - val_accuracy: 0.5347 - val_loss: 1.4651\n",
            "Epoch 4/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5915 - loss: 1.3205 - val_accuracy: 0.6146 - val_loss: 1.2461\n",
            "Epoch 5/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6525 - loss: 1.1224 - val_accuracy: 0.6562 - val_loss: 1.0924\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6458 - loss: 1.0882  \n",
            "Loss:     1.06\n",
            "Accuracy: 66.39%\n"
          ]
        }
      ],
      "source": [
        "# 1. Decreasing the learning rate\n",
        "\n",
        "# Decreasing the learning rate generally makes the training process slower but can help the model converge\n",
        "# to a better solution by taking smaller steps in the direction of the minimum of the loss function.\n",
        "# It can prevent overshooting the minimum, which can happen with a large learning rate.\n",
        "# The default learning rate for the SGD optimizer in Keras is 0.01.\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Input(shape=(64,)))  # Input tensor specifying the shape\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Hidden layer\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(10, activation='softmax'))  # 10 neurons, softmax activation\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # Loss function\n",
        "    optimizer=SGD(learning_rate=0.001), # Optimizer\n",
        "    metrics=['accuracy'] # Metrics to evaluate the model\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, # Training data\n",
        "    y_train, # Training labels\n",
        "    epochs=5, # Number of epochs\n",
        "    batch_size=32, # Number of samples per batch\n",
        "    validation_split=0.2 # Use 20% of the data for validation\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Loss:     {loss:.2f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "epWCvw1gK4aT",
        "outputId": "3338432b-0a7c-4e2f-af88-884eeacd1006"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1816 - loss: 7.1565 - val_accuracy: 0.1736 - val_loss: 2.1192\n",
            "Epoch 2/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3259 - loss: 1.9249 - val_accuracy: 0.3715 - val_loss: 1.6884\n",
            "Epoch 3/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3550 - loss: 1.7519 - val_accuracy: 0.3090 - val_loss: 1.7817\n",
            "Epoch 4/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3411 - loss: 1.8092 - val_accuracy: 0.3993 - val_loss: 1.6230\n",
            "Epoch 5/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3600 - loss: 1.6253 - val_accuracy: 0.3924 - val_loss: 1.5063\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4582 - loss: 1.3675  \n",
            "Loss:     1.42\n",
            "Accuracy: 42.50%\n"
          ]
        }
      ],
      "source": [
        "# 2. Increasing the learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Input(shape=(64,)))  # Input tensor specifying the shape\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Hidden layer\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(10, activation='softmax'))  # 10 neurons, softmax activation\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # Loss function\n",
        "    optimizer=SGD(learning_rate=0.1), # Optimizer with increased learning rate\n",
        "    metrics=['accuracy'] # Metrics to evaluate the model\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, # Training data\n",
        "    y_train, # Training labels\n",
        "    epochs=5, # Number of epochs\n",
        "    batch_size=32, # Number of samples per batch\n",
        "    validation_split=0.2 # Use 20% of the data for validation\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Loss:     {loss:.2f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "9Yw1YcZGK4aT",
        "outputId": "2c3dc71c-a2e3-48ea-fec1-cfb07aca6bb5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4099 - loss: 2.5150 - val_accuracy: 0.8715 - val_loss: 0.4457\n",
            "Epoch 2/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.3919 - val_accuracy: 0.8854 - val_loss: 0.3182\n",
            "Epoch 3/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1535 - val_accuracy: 0.9306 - val_loss: 0.2113\n",
            "Epoch 4/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9454 - loss: 0.1714 - val_accuracy: 0.9479 - val_loss: 0.1712\n",
            "Epoch 5/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.0978 - val_accuracy: 0.9618 - val_loss: 0.1229\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.1378  \n",
            "Loss:     0.16\n",
            "Accuracy: 95.00%\n"
          ]
        }
      ],
      "source": [
        "# 3. SGD with momentum\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Input(shape=(64,)))  # Input tensor specifying the shape\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Hidden layer\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(10, activation='softmax'))  # 10 neurons, softmax activation\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # Loss function\n",
        "    optimizer=SGD(learning_rate=0.01,momentum=0.9), # Optimizer\n",
        "    metrics=['accuracy'] # Metrics to evaluate the model\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, # Training data\n",
        "    y_train, # Training labels\n",
        "    epochs=5, # Number of epochs\n",
        "    batch_size=32, # Number of samples per batch\n",
        "    validation_split=0.2 # Use 20% of the data for validation\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Loss:     {loss:.2f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQWuo_Z4K4aT"
      },
      "source": [
        "Next, let's try a more advanced optimizer. Adam is likely the most popular optimizer for deep learning. It is an adaptive learning rate optimizer, which means that it automatically adjusts the learning rate based on how the training is going. This can be very useful, as it means that we don't need to manually tune the learning rate. Let's see how it performs on our model.\n",
        "\n",
        "\n",
        "1. Replace the SGD optimizer by the Adam optimizer from keras and run it\n",
        "  with the default parameters.\n",
        "\n",
        "2. Add another hidden layer with ReLU activation and 64 neurons. Does it improve the model performance?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "D3AAXGQKK4aT",
        "outputId": "0ddf321e-b47d-4c08-944a-4d990a5706d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,970\u001b[0m (35.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> (35.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2463 - loss: 4.3450 - val_accuracy: 0.7014 - val_loss: 1.0285\n",
            "Epoch 2/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7714 - loss: 0.7356 - val_accuracy: 0.8438 - val_loss: 0.5205\n",
            "Epoch 3/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.3456 - val_accuracy: 0.8819 - val_loss: 0.3567\n",
            "Epoch 4/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.2071 - val_accuracy: 0.8958 - val_loss: 0.2928\n",
            "Epoch 5/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.1570 - val_accuracy: 0.9236 - val_loss: 0.2506\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9670 - loss: 0.1395  \n",
            "Loss:     0.17\n",
            "Accuracy: 95.00%\n"
          ]
        }
      ],
      "source": [
        "# Adam optimizer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Input(shape=(64,)))  # Input tensor specifying the shape\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Hidden layer\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(10, activation='softmax'))  # 10 neurons, softmax activation\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # Loss function\n",
        "    optimizer=Adam(), # Optimizer\n",
        "    metrics=['accuracy'] # Metrics to evaluate the model\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, # Training data\n",
        "    y_train, # Training labels\n",
        "    epochs=5, # Number of epochs\n",
        "    batch_size=32, # Number of samples per batch\n",
        "    validation_split=0.2 # Use 20% of the data for validation\n",
        ")\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Loss:     {loss:.2f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBxy8M_sK4aT",
        "outputId": "9cd447bc-f5fd-485b-f918-fb73171b4a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3472 - loss: 1.9147 - val_accuracy: 0.7986 - val_loss: 0.6746\n",
            "Epoch 2/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.5299 - val_accuracy: 0.8819 - val_loss: 0.3432\n",
            "Epoch 3/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9366 - loss: 0.2214 - val_accuracy: 0.9444 - val_loss: 0.2066\n",
            "Epoch 4/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9631 - loss: 0.1548 - val_accuracy: 0.9236 - val_loss: 0.2139\n",
            "Epoch 5/5\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0851 - val_accuracy: 0.9236 - val_loss: 0.1762\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1058  \n",
            "Loss:     0.12\n",
            "Accuracy: 95.56%\n"
          ]
        }
      ],
      "source": [
        "# Extra hidden layer\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Input(shape=(64,)))  # Input tensor specifying the shape\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Hidden layer\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Hidden layer\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "# Hidden layer\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurons, ReLU activation\n",
        "\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(10, activation='softmax'))  # 10 neurons, softmax activation\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # Loss function\n",
        "    optimizer=Adam(), # Optimizer\n",
        "    metrics=['accuracy'] # Metrics to evaluate the model\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, # Training data\n",
        "    y_train, # Training labels\n",
        "    epochs=5, # Number of epochs\n",
        "    batch_size=32, # Number of samples per batch\n",
        "    validation_split=0.2 # Use 20% of the data for validation\n",
        ")\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Loss:     {loss:.2f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results:\n",
        "\n",
        "\n",
        "* Original SGD (default learning rate 0.01): Achieved an accuracy of approximately 93.33%.\n",
        "* SGD with decreased learning rate (0.001): The accuracy dropped significantly to around 66.39%. This shows that a learning rate that is too small can lead to very slow convergence or getting stuck in a poor local minimum within the limited number of epochs.\n",
        "* SGD with increased learning rate (0.1): The accuracy was also lower, around 42.50%. A learning rate that is too large can cause the optimization process to overshoot the minimum of the loss function and even diverge.\n",
        "* SGD with momentum (learning rate 0.01, momentum 0.9): The accuracy improved to 95.00%. Adding momentum helps accelerate SGD in the relevant direction and dampens oscillations, leading to faster and sometimes better convergence.\n",
        "* Adam optimizer (default settings): The accuracy reached 95.00%. Adam is an adaptive optimizer that adjusts the learning rate for each parameter, often leading to good performance without manual tuning of the learning rate.\n",
        "* Adam optimizer with an extra hidden layer: The accuracy slightly improved to 95.56%. Adding more layers can increase the model's capacity to learn more complex patterns, potentially leading to better performance if the added complexity is warranted by the data and doesn't lead to overfitting.\n",
        "\n",
        "Conculusion: Using a learning rate that is too high or too low for basic SGD can significantly hurt performance. Adding momentum to SGD or using an adaptive optimizer like Adam can improve the training process and lead to better accuracy. Adding more layers can also improve performance, as seen with the Adam optimizer, but it's not guaranteed and depends on the dataset and model complexity."
      ],
      "metadata": {
        "id": "38wTiOfoul0I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16-dFP60K4aT"
      },
      "source": [
        "### Exercises: Forward Pass and Generalization\n",
        "\n",
        "Let's look in more detail at how the model makes predictions on the test set. We will walk through each step of making predictions, examining exactly what's going on.\n",
        "\n",
        "To start, we will apply our model to the test set, and look at what we get as output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puZEu0w_K4aT"
      },
      "outputs": [],
      "source": [
        "predictions_tf = model(X_test)\n",
        "predictions_tf[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTZZU6jvK4af"
      },
      "outputs": [],
      "source": [
        "type(predictions_tf), predictions_tf.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZREXcnVDK4af"
      },
      "source": [
        "The raw output of the model is a tensor of shape `(360, 10)`. This means that we have 360 samples, and for each sample we have 10 values. Each of these values represents the probability that the sample belongs to a given class. This means that we have 10 probabilities for each sample, and the sum of these probabilities is 1. We can confirm this by summing the probabilities for each sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDZY7N8K4af"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.reduce_sum(predictions_tf, axis=1)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "KYGMZuzCK4af"
      },
      "source": [
        "...okay, there might be a small rounding error here and there. This is to do with how floating point numbers are represented in computers, and it's not something we need to worry about for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnYhGw5QK4ag"
      },
      "source": [
        "We can also extract the label with the highest probability using the tensorflow API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edYNZv05K4ag"
      },
      "outputs": [],
      "source": [
        "predicted_labels_tf = tf.argmax(predictions_tf, axis=1)\n",
        "predicted_labels_tf[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cwuV756lK4ag"
      },
      "source": [
        "One helpful aspect of this approach is that we don't just get the prediction, but also a sense of how confident the model is in its prediction. To see this in practice, let's take a look at some of the predictions the model is highly confident about (i.e. a lot of the probability mass is on one class):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRlL71bZK4ag"
      },
      "outputs": [],
      "source": [
        "# Get the values corresponding to the predicted labels for each sample\n",
        "predicted_values_tf = tf.reduce_max(predictions_tf, axis=1)\n",
        "\n",
        "# Get the indices of the samples with the highest predicted values\n",
        "most_confident_indices_tf = tf.argsort(predicted_values_tf, direction='DESCENDING').numpy()[:9]\n",
        "\n",
        "# Get the 9 most confident samples\n",
        "most_confident_samples_tf = X_test[most_confident_indices_tf]\n",
        "\n",
        "# Get the true labels for the 9 most confident samples\n",
        "most_confident_labels_tf = np.argmax(y_test[most_confident_indices_tf], axis=1)\n",
        "\n",
        "# Plot the 9 most confident samples\n",
        "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(most_confident_samples_tf[i].reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f\"{most_confident_labels_tf[i]}\")\n",
        "\n",
        "    # Removing axis labels\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVpZAXryK4ag"
      },
      "source": [
        "## Impact of Initialization\n",
        "\n",
        "Let's study the impact of a bad initialization when training\n",
        "a deep feed forward network.\n",
        "\n",
        "By default, Keras dense layers use the \"Glorot Uniform\" initialization\n",
        "strategy to initialize the weight matrices:\n",
        "\n",
        "- each weight coefficient is randomly sampled from [-scale, scale]\n",
        "- scale is proportional to $\\frac{1}{\\sqrt{n_{in} + n_{out}}}$\n",
        "\n",
        "This strategy is known to work well to initialize deep neural networks\n",
        "with \"tanh\" or \"relu\" activation functions and then trained with\n",
        "standard SGD.\n",
        "\n",
        "To assess the impact of initialization let us plug an alternative init\n",
        "scheme into a 2 hidden layers networks with \"tanh\" activations.\n",
        "For the sake of the example let's use normal distributed weights\n",
        "with a manually adjustable scale (standard deviation) and see the\n",
        "impact the scale value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqriLEkIK4ag"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "input_dim = 64\n",
        "hidden_dim = 64\n",
        "output_dim = 10\n",
        "\n",
        "normal_init = initializers.TruncatedNormal(stddev=0.01, seed=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\",\n",
        "                kernel_initializer=normal_init))\n",
        "model.add(Dense(hidden_dim, activation=\"tanh\",\n",
        "                kernel_initializer=normal_init))\n",
        "model.add(Dense(output_dim, activation=\"softmax\",\n",
        "                kernel_initializer=normal_init))\n",
        "\n",
        "model.compile(optimizer=optimizers.SGD(learning_rate=0.1),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4a1sNGXK4ah"
      },
      "outputs": [],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR_4xHKUK4ah"
      },
      "source": [
        "Let's have a look at the parameters of the first layer after initialization but before any training has happened:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO6hieQ6K4ah"
      },
      "outputs": [],
      "source": [
        "model.layers[0].weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMNxMvksK4ah"
      },
      "outputs": [],
      "source": [
        "w = model.layers[0].weights[0].numpy()\n",
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J58uxtasK4ah"
      },
      "outputs": [],
      "source": [
        "w.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJkz58mLK4ah"
      },
      "outputs": [],
      "source": [
        "b = model.layers[0].weights[1].numpy()\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwQ3NOs5K4ah"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=15, batch_size=32)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(history.history['loss'], label=\"Truncated Normal init\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7xtjmzmK4ai"
      },
      "source": [
        "Once the model has been fit, the weights have been updated and notably the biases are no longer 0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsN3WhVFK4ai"
      },
      "outputs": [],
      "source": [
        "model.layers[0].weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbLDHFRPK4ai"
      },
      "source": [
        "#### Questions:\n",
        "\n",
        "- Try the following initialization schemes and see whether\n",
        "  the SGD algorithm can successfully train the network or\n",
        "  not:\n",
        "  \n",
        "  - a very small e.g. `stddev=1e-3`\n",
        "  - a larger scale e.g. `stddev=1` or `10`\n",
        "  - initialize all weights to 0 (constant initialization)\n",
        "  \n",
        "- What do you observe? Can you find an explanation for those\n",
        "  outcomes?\n",
        "\n",
        "- Are more advanced solvers such as SGD with momentum or Adam able\n",
        "  to deal better with such bad initializations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlQFgX1eK4ai"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    }
  ],
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "version": 3,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}